{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 652,
     "status": "ok",
     "timestamp": 1737964782015,
     "user": {
      "displayName": "ashfaq hoq",
      "userId": "04580735236194054551"
     },
     "user_tz": -360
    },
    "id": "sC2ZWGEhbP2P"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import save_image\n",
    "from torchsummary import summary\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1737964782691,
     "user": {
      "displayName": "ashfaq hoq",
      "userId": "04580735236194054551"
     },
     "user_tz": -360
    },
    "id": "NpB1YGkPbZK0"
   },
   "outputs": [],
   "source": [
    "class Disc_Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super(Disc_Block, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels, out_channels, 4, stride, 1, bias=False, padding_mode=\"reflect\"\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1737964782691,
     "user": {
      "displayName": "ashfaq hoq",
      "userId": "04580735236194054551"
     },
     "user_tz": -360
    },
    "id": "tq73KsXrehpZ"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3, features=[64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels * 2,\n",
    "                features[0],\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                padding_mode=\"reflect\",\n",
    "            ),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "        layers = []\n",
    "        in_channels = features[0]\n",
    "        for feature in features[1:]:\n",
    "            layers.append(\n",
    "                Disc_Block(in_channels, feature, stride=1 if feature == features[-1] else 2),\n",
    "            )\n",
    "            in_channels = feature\n",
    "\n",
    "        layers.append(\n",
    "            nn.Conv2d(\n",
    "                in_channels, 1, kernel_size=4, stride=1, padding=1, padding_mode=\"reflect\"\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat([x, y], dim=1)\n",
    "        x = self.initial(x)\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1737964782691,
     "user": {
      "displayName": "ashfaq hoq",
      "userId": "04580735236194054551"
     },
     "user_tz": -360
    },
    "id": "SKXZ0alde9IQ"
   },
   "outputs": [],
   "source": [
    "# def test():\n",
    "#     x = torch.randn((1, 3, 256, 256))\n",
    "#     y = torch.randn((1, 3, 256, 256))\n",
    "#     model = Discriminator(in_channels=3)\n",
    "#     preds = model(x, y)\n",
    "#     print(model)\n",
    "#     print(preds.shape)\n",
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1737964782692,
     "user": {
      "displayName": "ashfaq hoq",
      "userId": "04580735236194054551"
     },
     "user_tz": -360
    },
    "id": "yetp9jnBe9rL",
    "outputId": "99be3eb6-013f-4b3d-8ef7-07221457e6c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (initial): Sequential(\n",
      "    (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (model): Sequential(\n",
      "    (0): CNNBlock(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False, padding_mode=reflect)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.2)\n",
      "      )\n",
      "    )\n",
      "    (1): CNNBlock(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False, padding_mode=reflect)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.2)\n",
      "      )\n",
      "    )\n",
      "    (2): CNNBlock(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False, padding_mode=reflect)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): LeakyReLU(negative_slope=0.2)\n",
      "      )\n",
      "    )\n",
      "    (3): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "  )\n",
      ")\n",
      "torch.Size([1, 1, 30, 30])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1737964782692,
     "user": {
      "displayName": "ashfaq hoq",
      "userId": "04580735236194054551"
     },
     "user_tz": -360
    },
    "id": "h6hYJKtTe-Nm",
    "outputId": "213bdfe5-8ac3-4e49-80d1-5c03eea4864c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 128, 128]           6,208\n",
      "         LeakyReLU-2         [-1, 64, 128, 128]               0\n",
      "            Conv2d-3          [-1, 128, 64, 64]         131,072\n",
      "       BatchNorm2d-4          [-1, 128, 64, 64]             256\n",
      "         LeakyReLU-5          [-1, 128, 64, 64]               0\n",
      "          CNNBlock-6          [-1, 128, 64, 64]               0\n",
      "            Conv2d-7          [-1, 256, 32, 32]         524,288\n",
      "       BatchNorm2d-8          [-1, 256, 32, 32]             512\n",
      "         LeakyReLU-9          [-1, 256, 32, 32]               0\n",
      "         CNNBlock-10          [-1, 256, 32, 32]               0\n",
      "           Conv2d-11          [-1, 512, 31, 31]       2,097,152\n",
      "      BatchNorm2d-12          [-1, 512, 31, 31]           1,024\n",
      "        LeakyReLU-13          [-1, 512, 31, 31]               0\n",
      "         CNNBlock-14          [-1, 512, 31, 31]               0\n",
      "           Conv2d-15            [-1, 1, 30, 30]           8,193\n",
      "================================================================\n",
      "Total params: 2,768,705\n",
      "Trainable params: 2,768,705\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 147456.00\n",
      "Forward/backward pass size (MB): 55.02\n",
      "Params size (MB): 10.56\n",
      "Estimated Total Size (MB): 147521.58\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = Discriminator(in_channels=3)\n",
    "summary(model, [(3, 256, 256), (3, 256, 256)])  # Provide input shapes for both `x` and `y`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1737964782692,
     "user": {
      "displayName": "ashfaq hoq",
      "userId": "04580735236194054551"
     },
     "user_tz": -360
    },
    "id": "AebkXybGjdii"
   },
   "outputs": [],
   "source": [
    "class Gen_Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, down=True, act=\"relu\", use_dropout=False):\n",
    "        super(Gen_Block, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False, padding_mode=\"reflect\")\n",
    "            if down\n",
    "            else nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU() if act == \"relu\" else nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "        self.use_dropout = use_dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.down = down\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return self.dropout(x) if self.use_dropout else x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1737964782692,
     "user": {
      "displayName": "ashfaq hoq",
      "userId": "04580735236194054551"
     },
     "user_tz": -360
    },
    "id": "ofgHk_x8nR1L"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels=3, features=64):\n",
    "        super().__init__()\n",
    "        self.initial_down = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, features, 4, 2, 1, padding_mode=\"reflect\"),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.down1 = Gen_Block(features, features * 2, down=True, act=\"leaky\", use_dropout=False)\n",
    "        self.down2 = Gen_Block(\n",
    "            features * 2, features * 4, down=True, act=\"leaky\", use_dropout=False\n",
    "        )\n",
    "        self.down3 = Gen_Block(\n",
    "            features * 4, features * 8, down=True, act=\"leaky\", use_dropout=False\n",
    "        )\n",
    "        self.down4 = Gen_Block(\n",
    "            features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False\n",
    "        )\n",
    "        self.down5 = Gen_Block(\n",
    "            features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False\n",
    "        )\n",
    "        self.down6 = Gen_Block(\n",
    "            features * 8, features * 8, down=True, act=\"leaky\", use_dropout=False\n",
    "        )\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(features * 8, features * 8, 4, 2, 1), nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.up1 = Gen_Block(features * 8, features * 8, down=False, act=\"relu\", use_dropout=True)\n",
    "        self.up2 = Gen_Block(\n",
    "            features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=True\n",
    "        )\n",
    "        self.up3 = Gen_Block(\n",
    "            features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=True\n",
    "        )\n",
    "        self.up4 = Gen_Block(\n",
    "            features * 8 * 2, features * 8, down=False, act=\"relu\", use_dropout=False\n",
    "        )\n",
    "        self.up5 = Gen_Block(\n",
    "            features * 8 * 2, features * 4, down=False, act=\"relu\", use_dropout=False\n",
    "        )\n",
    "        self.up6 = Gen_Block(\n",
    "            features * 4 * 2, features * 2, down=False, act=\"relu\", use_dropout=False\n",
    "        )\n",
    "        self.up7 = Gen_Block(features * 2 * 2, features, down=False, act=\"relu\", use_dropout=False)\n",
    "        self.final_up = nn.Sequential(\n",
    "            nn.ConvTranspose2d(features * 2, in_channels, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        d1 = self.initial_down(x)\n",
    "        d2 = self.down1(d1)\n",
    "        d3 = self.down2(d2)\n",
    "        d4 = self.down3(d3)\n",
    "        d5 = self.down4(d4)\n",
    "        d6 = self.down5(d5)\n",
    "        d7 = self.down6(d6)\n",
    "        bottleneck = self.bottleneck(d7)\n",
    "        up1 = self.up1(bottleneck)\n",
    "        up2 = self.up2(torch.cat([up1, d7], 1))\n",
    "        up3 = self.up3(torch.cat([up2, d6], 1))\n",
    "        up4 = self.up4(torch.cat([up3, d5], 1))\n",
    "        up5 = self.up5(torch.cat([up4, d4], 1))\n",
    "        up6 = self.up6(torch.cat([up5, d3], 1))\n",
    "        up7 = self.up7(torch.cat([up6, d2], 1))\n",
    "        return self.final_up(torch.cat([up7, d1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1229,
     "status": "ok",
     "timestamp": 1737964783917,
     "user": {
      "displayName": "ashfaq hoq",
      "userId": "04580735236194054551"
     },
     "user_tz": -360
    },
    "id": "UGFXaef5nZ6_",
    "outputId": "8c4af40c-6248-4280-c0cc-26b6f4afd613"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# def test():\n",
    "#     x = torch.randn((1, 3, 256, 256))\n",
    "#     model = Generator(in_channels=3, features=64)\n",
    "#     preds = model(x)\n",
    "#     print(preds.shape)\n",
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1737964783917,
     "user": {
      "displayName": "ashfaq hoq",
      "userId": "04580735236194054551"
     },
     "user_tz": -360
    },
    "id": "_lbsMBuRnh5T"
   },
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "TRAIN_DIR = \"/root/.cache/kagglehub/datasets/tanvirnwu/loli-street-low-light-image-enhancement-of-street/versions/1/LoLI-Street Dataset/Train\"\n",
    "VAL_DIR = \"/root/.cache/kagglehub/datasets/tanvirnwu/loli-street-low-light-image-enhancement-of-street/versions/1/LoLI-Street Dataset/Val\"\n",
    "LEARNING_RATE = 2e-4\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 2\n",
    "IMAGE_SIZE = 256\n",
    "CHANNELS_IMG = 3\n",
    "L1_LAMBDA = 100\n",
    "LAMBDA_GP = 10\n",
    "NUM_EPOCHS = 50\n",
    "LOAD_MODEL = False\n",
    "SAVE_MODEL = False\n",
    "CHECKPOINT_DISC = \"disc.pth.tar\"\n",
    "CHECKPOINT_GEN = \"gen.pth.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1737964783917,
     "user": {
      "displayName": "ashfaq hoq",
      "userId": "04580735236194054551"
     },
     "user_tz": -360
    },
    "id": "lorvDtvVXdEu"
   },
   "outputs": [],
   "source": [
    "both_transform = A.Compose(\n",
    "    [A.Resize(width=256, height=256),], additional_targets={\"image0\": \"image\"},\n",
    ")\n",
    "\n",
    "transform_only_input = A.Compose(\n",
    "    [\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.ColorJitter(p=0.2),\n",
    "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255.0,),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_only_mask = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255.0,),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1737964783917,
     "user": {
      "displayName": "ashfaq hoq",
      "userId": "04580735236194054551"
     },
     "user_tz": -360
    },
    "id": "UBldK0k0av9X"
   },
   "outputs": [],
   "source": [
    "class MapDataset(Dataset):\n",
    "  def __init__(self, root_dir):\n",
    "    self.high_dir = os.path.join(root_dir, \"high\")\n",
    "    self.low_dir = os.path.join(root_dir, \"low\")\n",
    "    self.high_images = sorted(os.listdir(self.high_dir))\n",
    "    self.low_images = sorted(os.listdir(self.low_dir))\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(os.listdir(self.high_dir))\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    high_path = os.path.join(self.high_dir, self.high_images[index])\n",
    "    low_path = os.path.join(self.low_dir, self.low_images[index])\n",
    "\n",
    "    high_image = np.array(Image.open(high_path))\n",
    "    low_image = np.array(Image.open(low_path))\n",
    "\n",
    "    augmentations = both_transform(image=high_image, image0=low_image)\n",
    "    high_image = augmentations[\"image\"]\n",
    "    low_image = augmentations[\"image0\"]\n",
    "\n",
    "    high_image = transform_only_input(image=high_image)[\"image\"]\n",
    "    low_image = transform_only_mask(image=low_image)[\"image\"]\n",
    "\n",
    "    return high_image, low_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 3507,
     "status": "ok",
     "timestamp": 1737964787419,
     "user": {
      "displayName": "ashfaq hoq",
      "userId": "04580735236194054551"
     },
     "user_tz": -360
    },
    "id": "HPw_eOvcf9x_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Notebooks\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/tanvirnwu/loli-street-low-light-image-enhancement-of-street?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.63G/2.63G [16:16<00:00, 2.89MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"tanvirnwu/loli-street-low-light-image-enhancement-of-street\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1737964787421,
     "user": {
      "displayName": "ashfaq hoq",
      "userId": "04580735236194054551"
     },
     "user_tz": -360
    },
    "id": "60JXRmdLh06j",
    "outputId": "7c43f3d2-717f-4878-e5d2-2fcefbe6f2b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Path: /root/.cache/kagglehub/datasets/tanvirnwu/loli-street-low-light-image-enhancement-of-street/versions/1\n",
      "Contents of the dataset root folder: ['LoLI-Street Dataset']\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Path:\", path)\n",
    "print(\"Contents of the dataset root folder:\", os.listdir(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1737964787421,
     "user": {
      "displayName": "ashfaq hoq",
      "userId": "04580735236194054551"
     },
     "user_tz": -360
    },
    "id": "c1V5zNPliBW_",
    "outputId": "70ceb493-92e4-44b4-a856-47635fac6735"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of LoLI-Street Dataset: ['Val', 'Test', 'YOLO Annotations', 'Train']\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"/root/.cache/kagglehub/datasets/tanvirnwu/loli-street-low-light-image-enhancement-of-street/versions/1\"\n",
    "loli_dataset_folder = os.path.join(dataset_path, \"LoLI-Street Dataset\")\n",
    "print(\"Contents of LoLI-Street Dataset:\", os.listdir(loli_dataset_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1737964787422,
     "user": {
      "displayName": "ashfaq hoq",
      "userId": "04580735236194054551"
     },
     "user_tz": -360
    },
    "id": "lG03LmbkhanZ"
   },
   "outputs": [],
   "source": [
    "train_path = \"/root/.cache/kagglehub/datasets/tanvirnwu/loli-street-low-light-image-enhancement-of-street/versions/1/LoLI-Street Dataset/Train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1mM4RsmkCIEcsRHreJ5YGhTtp2Q0jOGdR"
    },
    "executionInfo": {
     "elapsed": 4455,
     "status": "ok",
     "timestamp": 1737964791868,
     "user": {
      "displayName": "ashfaq hoq",
      "userId": "04580735236194054551"
     },
     "user_tz": -360
    },
    "id": "wAwQH4VGfyb4",
    "outputId": "18e55ab8-a17b-4168-e4ba-60cab846b925"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = MapDataset(train_path)\n",
    "loader = DataLoader(dataset, batch_size=5)\n",
    "# Convert tensors back to PIL images\n",
    "to_pil = transforms.ToPILImage()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize the entire batch of images\n",
    "for x, y in loader:\n",
    "  # Denormalize (convert back to range [0, 1] for visualization)\n",
    "  x = x * 0.5 + 0.5\n",
    "  y = y * 0.5 + 0.5\n",
    "\n",
    "  # Number of images in the batch\n",
    "  batch_size = x.shape[0]\n",
    "\n",
    "  # Create a subplot with enough space for all images in the batch\n",
    "  fig, axes = plt.subplots(batch_size, 2, figsize=(10, batch_size * 5))\n",
    "\n",
    "  # Loop through each image in the batch\n",
    "  for i in range(batch_size):\n",
    "    # Convert PyTorch tensors to numpy for Matplotlib\n",
    "    x_np = x[i].permute(1, 2, 0).cpu().numpy()\n",
    "    y_np = y[i].permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "    # Plot input and target images\n",
    "    axes[i, 0].imshow(x_np)\n",
    "    axes[i, 0].set_title(f\"Input Image {i+1}\")\n",
    "    axes[i, 0].axis(\"off\")\n",
    "\n",
    "    axes[i, 1].imshow(y_np)\n",
    "    axes[i, 1].set_title(f\"Target Image {i+1}\")\n",
    "    axes[i, 1].axis(\"off\")\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "  break  # Remove this if you want to see multiple batches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "\n",
    "def save_some_examples(gen, val_loader, epoch, folder):\n",
    "    x, y = next(iter(val_loader))\n",
    "    x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "    gen.eval()\n",
    "    with torch.no_grad():\n",
    "        y_fake = gen(x)\n",
    "        y_fake = y_fake * 0.5 + 0.5  # remove normalization#\n",
    "        save_image(y_fake, folder + f\"/y_gen_{epoch}.png\")\n",
    "        save_image(x * 0.5 + 0.5, folder + f\"/input_{epoch}.png\")\n",
    "        if epoch == 1:\n",
    "            save_image(y * 0.5 + 0.5, folder + f\"/label_{epoch}.png\")\n",
    "    gen.train()\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "    # If we don't do this then it will just have learning rate of old checkpoint\n",
    "    # and it will lead to many hours of debugging \\:\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "executionInfo": {
     "elapsed": 385,
     "status": "ok",
     "timestamp": 1737964792250,
     "user": {
      "displayName": "ashfaq hoq",
      "userId": "04580735236194054551"
     },
     "user_tz": -360
    },
    "id": "O4f0vtAbgoz-"
   },
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "def train_fn(disc, gen, loader, opt_disc, opt_gen, l1_loss, bce, g_scaler, d_scaler):\n",
    "  loop = tqdm(loader, leave=True)\n",
    "\n",
    "  for idx, (x, y) in enumerate(loop):\n",
    "    x = x.to(DEVICE)\n",
    "    y = y.to(DEVICE)\n",
    "\n",
    "    # Train Discriminator\n",
    "    with torch.cuda.amp.autocast():\n",
    "        y_fake = gen(x)\n",
    "        D_real = disc(x, y)\n",
    "        D_real_loss = bce(D_real, torch.ones_like(D_real))\n",
    "        D_fake = disc(x, y_fake.detach())\n",
    "        D_fake_loss = bce(D_fake, torch.zeros_like(D_fake))\n",
    "        D_loss = (D_real_loss + D_fake_loss) / 2\n",
    "\n",
    "    disc.zero_grad()\n",
    "    d_scaler.scale(D_loss).backward()\n",
    "    d_scaler.step(opt_disc)\n",
    "    d_scaler.update()\n",
    "\n",
    "    # Train generator\n",
    "    with torch.cuda.amp.autocast():\n",
    "        D_fake = disc(x, y_fake)\n",
    "        G_fake_loss = bce(D_fake, torch.ones_like(D_fake))\n",
    "        L1 = l1_loss(y_fake, y) * L1_LAMBDA\n",
    "        G_loss = G_fake_loss + L1\n",
    "\n",
    "    opt_gen.zero_grad()\n",
    "    g_scaler.scale(G_loss).backward()\n",
    "    g_scaler.step(opt_gen)\n",
    "    g_scaler.update()\n",
    "\n",
    "    if idx % 10 == 0:\n",
    "        loop.set_postfix(\n",
    "            D_real=torch.sigmoid(D_real).mean().item(),\n",
    "            D_fake=torch.sigmoid(D_fake).mean().item(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1737964792250,
     "user": {
      "displayName": "ashfaq hoq",
      "userId": "04580735236194054551"
     },
     "user_tz": -360
    },
    "id": "akV2_CwlwaOi"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "  disc = Discriminator(in_channels=3).to(DEVICE)\n",
    "  gen = Generator(in_channels=3, features=64).to(DEVICE)\n",
    "  opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999),)\n",
    "  opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "  BCE = nn.BCEWithLogitsLoss()\n",
    "  L1_LOSS = nn.L1Loss()\n",
    "\n",
    "  # if config.LOAD_MODEL:\n",
    "  #     load_checkpoint(\n",
    "  #         config.CHECKPOINT_GEN, gen, opt_gen, config.LEARNING_RATE,\n",
    "  #     )\n",
    "  #     load_checkpoint(\n",
    "  #         config.CHECKPOINT_DISC, disc, opt_disc, config.LEARNING_RATE,\n",
    "  #     )\n",
    "\n",
    "  train_dataset = MapDataset(root_dir=TRAIN_DIR)\n",
    "  train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "  )\n",
    "  g_scaler = torch.GradScaler()\n",
    "  d_scaler = torch.GradScaler()\n",
    "  val_dataset = MapDataset(root_dir=VAL_DIR)\n",
    "  val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "  for epoch in range(NUM_EPOCHS):\n",
    "      train_fn(\n",
    "          disc, gen, train_loader, opt_disc, opt_gen, L1_LOSS, BCE, g_scaler, d_scaler,\n",
    "      )\n",
    "\n",
    "      # if config.SAVE_MODEL and epoch % 5 == 0:\n",
    "      #       save_checkpoint(gen, opt_gen, filename=config.CHECKPOINT_GEN)\n",
    "      #       save_checkpoint(disc, opt_disc, filename=config.CHECKPOINT_DISC)\n",
    "\n",
    "      save_some_examples(gen, val_loader, epoch, folder=\"generated_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "ss_VaVf8xOSU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-3af7602a8a52>:24: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  g_scaler = torch.cuda.amp.GradScaler()\n",
      "<ipython-input-65-3af7602a8a52>:25: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  d_scaler = torch.cuda.amp.GradScaler()\n",
      "  0%|          | 0/1875 [00:00<?, ?it/s]<ipython-input-64-8084b074961f>:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "<ipython-input-64-8084b074961f>:26: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "  3%|▎         | 47/1875 [29:39<18:44:58, 36.92s/it, D_fake=0.24, D_real=0.779]"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uzTlrn8LxQJK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO7HhhwKieUyh+vTD1/+COv",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
